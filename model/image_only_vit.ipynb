{"cells":[{"cell_type":"markdown","metadata":{},"source":["* This notebook is a modified version of https://www.kaggle.com/code/markwijkhuizen/planttraits2024-eda-training-pub.\n","* Only the image inputs are used."]},{"cell_type":"markdown","metadata":{},"source":["# Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T01:40:25.705460Z","iopub.status.busy":"2024-04-18T01:40:25.704875Z","iopub.status.idle":"2024-04-18T01:40:25.714700Z","shell.execute_reply":"2024-04-18T01:40:25.713650Z","shell.execute_reply.started":"2024-04-18T01:40:25.705415Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import imageio.v3 as  imageio\n","import albumentations as A\n","\n","from albumentations.pytorch import ToTensorV2\n","from torch.utils.data import Dataset, DataLoader\n","from torch import nn\n","from tqdm.notebook import tqdm\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","from torchvision import transforms\n","\n","import torch\n","import timm\n","import glob\n","import torchmetrics\n","import time\n","import psutil\n","import os\n","import math\n","import warnings\n","\n","tqdm.pandas()"]},{"cell_type":"markdown","metadata":{},"source":["# Config"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T01:40:25.716721Z","iopub.status.busy":"2024-04-18T01:40:25.716439Z","iopub.status.idle":"2024-04-18T01:40:25.732815Z","shell.execute_reply":"2024-04-18T01:40:25.731819Z","shell.execute_reply.started":"2024-04-18T01:40:25.716698Z"},"trusted":true},"outputs":[],"source":["class Config():\n","    IMAGE_SIZE0 = 512\n","    IMAGE_SIZE = 224\n","    TARGET_COLUMNS = ['X4_mean', 'X11_mean', 'X18_mean', 'X50_mean', 'X26_mean', 'X3112_mean']\n","    TARGET_COLUMNS_TEST = ['X4', 'X11', 'X18', 'X50', 'X26', 'X3112']\n","    N_TARGETS = len(TARGET_COLUMNS)\n","    # Dataset\n","    RECOMPUTE_DATAFRAMES = False\n","    BATCH_SIZE = 96\n","    BATCH_SIZE_VAL = 128\n","    N_VAL_SAMPLES0 = 4096\n","    # Training\n","    LR_MAX = 1e-4\n","    WEIGHT_DECAY = 0.01\n","    N_EPOCHS = 8\n","    TRAIN_MODEL = True\n","    # Others\n","    IS_INTERACTIVE = os.environ['KAGGLE_KERNEL_RUN_TYPE'] == 'Interactive'\n","    SEED = 42\n","    EPS = 1e-6\n","    EPS_CUDA = torch.tensor([EPS]).to('cuda')\n","        \n","CONFIG = Config()"]},{"cell_type":"markdown","metadata":{},"source":["# Train DataFrame"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T01:40:25.734471Z","iopub.status.busy":"2024-04-18T01:40:25.734138Z","iopub.status.idle":"2024-04-18T01:40:29.028115Z","shell.execute_reply":"2024-04-18T01:40:29.027202Z","shell.execute_reply.started":"2024-04-18T01:40:25.734432Z"},"trusted":true},"outputs":[],"source":["if CONFIG.RECOMPUTE_DATAFRAMES:\n","    train0 = pd.read_csv('/kaggle/input/planttraits2024/train.csv')\n","\n","    # Add File Path\n","    train0['file_path'] = train0['id'].apply(lambda s: f'/kaggle/input/planttraits2024/train_images/{s}.jpeg')\n","\n","    # Reaed Raw Image JPEG Bytes\n","    train0['jpeg_bytes'] = train0['file_path'].progress_apply(lambda fp: open(fp, 'rb').read())\n","    \n","    # Save for Future Use\n","    train0.to_pickle('train.pkl')\n","else:\n","    train0 = pd.read_pickle('/kaggle/input/planttraits2024-eda-training-pub-dataset/train.pkl')\n","    \n","# Assign Medians\n","CONFIG.TARGET_MEDIANS = train0[CONFIG.TARGET_COLUMNS].median(axis=0).values"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T01:40:29.031974Z","iopub.status.busy":"2024-04-18T01:40:29.031271Z","iopub.status.idle":"2024-04-18T01:40:29.064113Z","shell.execute_reply":"2024-04-18T01:40:29.063043Z","shell.execute_reply.started":"2024-04-18T01:40:29.031937Z"},"trusted":true},"outputs":[],"source":["# Split train in train/val\n","train0 = train0.head(5000)\n","train, val = train_test_split(train0, test_size=0.2, shuffle=True, random_state=CONFIG.SEED)\n","\n","train = train.reset_index(drop=True)\n","val = val.reset_index(drop=True)"]},{"cell_type":"markdown","metadata":{},"source":["# Test DataFrame"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T01:40:29.066670Z","iopub.status.busy":"2024-04-18T01:40:29.066247Z","iopub.status.idle":"2024-04-18T01:40:30.002228Z","shell.execute_reply":"2024-04-18T01:40:30.001166Z","shell.execute_reply.started":"2024-04-18T01:40:29.066616Z"},"trusted":true},"outputs":[],"source":["if CONFIG.RECOMPUTE_DATAFRAMES:\n","    test = pd.read_csv('/kaggle/input/planttraits2024/test.csv')\n","\n","    # Add File Path\n","    test['file_path'] = test['id'].apply(lambda s: f'/kaggle/input/planttraits2024/test_images/{s}.jpeg')\n","\n","    # Reaed Raw Image JPEG Bytes\n","    test['jpeg_bytes'] = test['file_path'].progress_apply(lambda fp: open(fp, 'rb').read())\n","\n","    # Save for Future Use\n","    test.to_pickle('test.pkl')\n","else:\n","    test = pd.read_pickle('/kaggle/input/my-dataset/test (1).pkl')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T01:40:30.004809Z","iopub.status.busy":"2024-04-18T01:40:30.003984Z","iopub.status.idle":"2024-04-18T01:40:30.010083Z","shell.execute_reply":"2024-04-18T01:40:30.009086Z","shell.execute_reply.started":"2024-04-18T01:40:30.004773Z"},"trusted":true},"outputs":[],"source":["# Feature Columns\n","FEATURE_COLUMNS = test.columns.values[1:-2]\n","CONFIG.N_FEATURES = len(FEATURE_COLUMNS)\n","print(f'N_FEATURES: {CONFIG.N_FEATURES}')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T01:40:30.011796Z","iopub.status.busy":"2024-04-18T01:40:30.011417Z","iopub.status.idle":"2024-04-18T01:40:30.024397Z","shell.execute_reply":"2024-04-18T01:40:30.023544Z","shell.execute_reply.started":"2024-04-18T01:40:30.011763Z"},"trusted":true},"outputs":[],"source":["# Minimum/Maximum Based On Train 0.1% and 99.9%\n","CONFIG.V_MIN = train[CONFIG.TARGET_COLUMNS].quantile(0.001)\n","CONFIG.V_MAX = train[CONFIG.TARGET_COLUMNS].quantile(0.999)"]},{"cell_type":"markdown","metadata":{},"source":["# Labels"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T01:40:30.025845Z","iopub.status.busy":"2024-04-18T01:40:30.025571Z","iopub.status.idle":"2024-04-18T01:40:30.042499Z","shell.execute_reply":"2024-04-18T01:40:30.041569Z","shell.execute_reply.started":"2024-04-18T01:40:30.025821Z"},"trusted":true},"outputs":[],"source":["# Labels Meta Data\n","target_name_meta = pd.read_csv('/kaggle/input/planttraits2024/target_name_meta.tsv', delimiter='\\t')\n","target_name_meta['trait_ID'] = target_name_meta['trait_ID'] + '_mean'\n","target_name_meta = target_name_meta.set_index('trait_ID').squeeze().to_dict()\n","\n","display(pd.Series(target_name_meta).to_frame())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T01:40:30.043838Z","iopub.status.busy":"2024-04-18T01:40:30.043523Z","iopub.status.idle":"2024-04-18T01:40:30.092792Z","shell.execute_reply":"2024-04-18T01:40:30.091937Z","shell.execute_reply.started":"2024-04-18T01:40:30.043806Z"},"trusted":true},"outputs":[],"source":["# Percentiles of features to use\n","percentiles = [\n","    0.001, 0.01,0.05,0.10,0.25,\n","    0.50,\n","    0.75,0.90,0.95,0.99, 0.999,\n","]\n","labels_describe_df = pd.DataFrame()\n","for target in CONFIG.TARGET_COLUMNS:\n","    labels_describe_df = pd.concat((\n","        labels_describe_df,\n","        train[target].describe(percentiles=percentiles).round(3)\n","    ), axis=1)\n","    \n","# Transpose DataFrame\n","labels_describe_df = labels_describe_df.T\n","    \n","# Minimum/Maximum Values\n","labels_describe_df.insert(4, 'v_min', CONFIG.V_MIN)\n","labels_describe_df.insert(16, 'v_max', CONFIG.V_MAX)\n","    \n","display(labels_describe_df)"]},{"cell_type":"markdown","metadata":{},"source":["# Plot outliers"]},{"cell_type":"markdown","metadata":{},"source":["# Filter Outliers"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T01:40:30.096675Z","iopub.status.busy":"2024-04-18T01:40:30.096395Z","iopub.status.idle":"2024-04-18T01:40:30.123533Z","shell.execute_reply":"2024-04-18T01:40:30.122585Z","shell.execute_reply.started":"2024-04-18T01:40:30.096652Z"},"trusted":true},"outputs":[],"source":["# Mask to exclude values outside of 0.1% - 99.9% range\n","def get_mask(df):\n","    lower = []\n","    higher = []\n","    mask = np.empty(shape=df[CONFIG.TARGET_COLUMNS].shape, dtype=bool)\n","    # Fill mask based on minimum/maximum values of sample submission\n","    for idx, (t, v_min, v_max) in enumerate(zip(CONFIG.TARGET_COLUMNS, CONFIG.V_MIN, CONFIG.V_MAX)):\n","        labels = df[t].values\n","        mask[:,idx] = ((labels > v_min) & (labels < v_max))\n","    return mask.min(axis=1)\n","\n","# Masks\n","CONFIG.MASK_TRAIN = get_mask(train)\n","CONFIG.MASK_VAL = get_mask(val)\n","# Masked DataFrames\n","train_mask = train[CONFIG.MASK_TRAIN].reset_index(drop=True)\n","val_mask = val[CONFIG.MASK_VAL].reset_index(drop=True)\n","# Add Number Of Steps\n","CONFIG.N_TRAIN_SAMPLES = len(train_mask)\n","CONFIG.N_VAL_SAMPLES = len(val_mask)\n","CONFIG.N_STEPS_PER_EPOCH = (CONFIG.N_TRAIN_SAMPLES // CONFIG.BATCH_SIZE)\n","CONFIG.N_VAL_STEPS_PER_EPOCH = math.ceil(CONFIG.N_VAL_SAMPLES / CONFIG.BATCH_SIZE_VAL)\n","CONFIG.N_STEPS = CONFIG.N_STEPS_PER_EPOCH * CONFIG.N_EPOCHS + 1\n","\n","for m, subset in zip([CONFIG.MASK_TRAIN, CONFIG.MASK_VAL], ['train', 'val']):\n","    print(f'===== {subset} shape: {m.shape} =====')\n","    print(f'{subset} \\t| # Masked Samples: {(1-m.mean())*CONFIG.N_TRAIN_SAMPLES:.0f}')\n","    print(f'{subset} \\t| % Masked Samples: {100-m.mean()*100:.3f}%')"]},{"cell_type":"markdown","metadata":{},"source":["# Label Normalization"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T01:40:30.125028Z","iopub.status.busy":"2024-04-18T01:40:30.124715Z","iopub.status.idle":"2024-04-18T01:40:30.129401Z","shell.execute_reply":"2024-04-18T01:40:30.128430Z","shell.execute_reply.started":"2024-04-18T01:40:30.124996Z"},"trusted":true},"outputs":[],"source":["# Log Scale Features\n","LOG_FEATURES = ['X11_mean', 'X18_mean', 'X50_mean', 'X26_mean', 'X3112_mean']"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T01:40:30.130891Z","iopub.status.busy":"2024-04-18T01:40:30.130558Z","iopub.status.idle":"2024-04-18T01:40:30.163993Z","shell.execute_reply":"2024-04-18T01:40:30.163131Z","shell.execute_reply.started":"2024-04-18T01:40:30.130866Z"},"trusted":true},"outputs":[],"source":["# Fill labels using normalization tool\n","def fill_y(y, df, normalize=False):\n","    for target_idx, target in enumerate(CONFIG.TARGET_COLUMNS):\n","        v = df[target]\n","        if normalize:\n","            # Log10 Transform\n","            if target in LOG_FEATURES:\n","                v = np.log10(v)\n","            # Shift To Have Zero Median\n","            Y_SHIFT[target_idx] = np.mean(v)\n","            v = v - np.median(v)\n","            # Uniform Variance\n","            Y_STD[target_idx] = np.std(v)\n","            v = v / np.std(v)\n","        # Assign to y_train\n","        y[:,target_idx] = v\n","\n","# Feature Scaler\n","Y_SHIFT = np.zeros(CONFIG.N_TARGETS)\n","Y_STD = np.zeros(CONFIG.N_TARGETS)\n","# Masked Labels\n","y_train_mask_raw = np.zeros_like(train_mask[CONFIG.TARGET_COLUMNS], dtype=np.float32)\n","y_train_mask = np.zeros_like(train_mask[CONFIG.TARGET_COLUMNS], dtype=np.float32)\n","y_val_mask = np.zeros_like(val_mask[CONFIG.TARGET_COLUMNS], dtype=np.float32)\n","# Fill Target Arrays\n","fill_y(y_train_mask_raw, train_mask, normalize=False)\n","fill_y(y_train_mask, train_mask, normalize=True)\n","fill_y(y_val_mask, val_mask, normalize=True)\n","# Values\n","display(pd.DataFrame({\n","    'y_shift': Y_SHIFT,\n","    'y_std': Y_STD\n","}, index=CONFIG.TARGET_COLUMNS))"]},{"cell_type":"markdown","metadata":{},"source":[" # Features"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T01:40:30.165312Z","iopub.status.busy":"2024-04-18T01:40:30.165026Z","iopub.status.idle":"2024-04-18T01:40:30.224153Z","shell.execute_reply":"2024-04-18T01:40:30.223324Z","shell.execute_reply.started":"2024-04-18T01:40:30.165272Z"},"trusted":true},"outputs":[],"source":["# Standard Scaler for Features\n","FEATURE_SCALER = StandardScaler()\n","\n","# Fit and transform on training features\n","train_features_mask = FEATURE_SCALER.fit_transform(train_mask[FEATURE_COLUMNS].values.astype(np.float32))\n","# Transform val/test features using scaler fitted on train data\n","val_features_mask = FEATURE_SCALER.transform(val_mask[FEATURE_COLUMNS].values.astype(np.float32))\n","test_features = FEATURE_SCALER.transform(test[FEATURE_COLUMNS].values.astype(np.float32))\n","# Convert Features to Torch Tensors\n","train_features_mask = torch.tensor(train_features_mask)\n","val_features_mask = torch.tensor(val_features_mask)\n","test_features = torch.tensor(test_features)"]},{"cell_type":"markdown","metadata":{},"source":["# Transforms"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T01:40:30.225553Z","iopub.status.busy":"2024-04-18T01:40:30.225245Z","iopub.status.idle":"2024-04-18T01:40:30.233786Z","shell.execute_reply":"2024-04-18T01:40:30.232803Z","shell.execute_reply.started":"2024-04-18T01:40:30.225528Z"},"trusted":true},"outputs":[],"source":["MEAN = np.array([0.485, 0.456, 0.406])\n","STD = np.array([0.229, 0.224, 0.225])\n","# Training Augmentations\n","TRAIN_TRANSFORMS = A.Compose([\n","        A.RandomSizedCrop(\n","            [int(0.85*CONFIG.IMAGE_SIZE0), CONFIG.IMAGE_SIZE0],\n","            CONFIG.IMAGE_SIZE, CONFIG.IMAGE_SIZE, w2h_ratio=1.0, p=1.0\n","        ),\n","        A.HorizontalFlip(p=0.50),\n","        A.RandomBrightnessContrast(brightness_limit=0.10, contrast_limit=0.10, p=0.50),\n","        A.ImageCompression(quality_lower=75, quality_upper=100, p=0.5),\n","        ToTensorV2(),\n","    ])\n","# Test Augmentations\n","VAL_TEST_TRANSFORMS = A.Compose([\n","        A.Resize(CONFIG.IMAGE_SIZE,CONFIG.IMAGE_SIZE),\n","        ToTensorV2(),\n","    ])"]},{"cell_type":"markdown","metadata":{},"source":["# Dataloader"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T01:40:30.235443Z","iopub.status.busy":"2024-04-18T01:40:30.235133Z","iopub.status.idle":"2024-04-18T01:40:30.249227Z","shell.execute_reply":"2024-04-18T01:40:30.248392Z","shell.execute_reply.started":"2024-04-18T01:40:30.235420Z"},"trusted":true},"outputs":[],"source":["class MyDataset(Dataset):\n","    def __init__(self, X_jpeg_bytes, y, features, transforms=None):\n","        self.X_jpeg_bytes = X_jpeg_bytes\n","        self.y = y\n","        self.features = features\n","        self.transforms = transforms\n","\n","    def __len__(self):\n","        return len(self.X_jpeg_bytes)\n","\n","    def __getitem__(self, index):\n","        X_sample = {\n","            'image': self.transforms(\n","                    image=imageio.imread(self.X_jpeg_bytes[index]),\n","                )['image'],\n","            'feature': self.features[index],\n","        }\n","        y_sample = self.y[index]\n","            \n","        return X_sample, y_sample"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T01:40:30.250431Z","iopub.status.busy":"2024-04-18T01:40:30.250163Z","iopub.status.idle":"2024-04-18T01:40:31.049054Z","shell.execute_reply":"2024-04-18T01:40:31.046736Z","shell.execute_reply.started":"2024-04-18T01:40:30.250408Z"},"trusted":true},"outputs":[],"source":["# Train\n","train_dataset = MyDataset(\n","    train_mask['jpeg_bytes'].values,\n","    y_train_mask,\n","    train_features_mask,\n","    TRAIN_TRANSFORMS,\n",")\n","\n","train_dataloader = DataLoader(\n","        train_dataset,\n","        batch_size=CONFIG.BATCH_SIZE,\n","        drop_last=True,\n","        num_workers=psutil.cpu_count(),\n","    )\n","train_dataloader_iter = iter(train_dataloader)\n","\n","# Validation\n","val_dataset = MyDataset(\n","    val_mask['jpeg_bytes'].values,\n","    y_val_mask,\n","    val_features_mask,\n","    VAL_TEST_TRANSFORMS,\n",")\n","val_dataloader = DataLoader(val_dataset, batch_size=CONFIG.BATCH_SIZE_VAL, drop_last=False)\n","\n","# Test\n","test_dataset = MyDataset(\n","    test['jpeg_bytes'].values,\n","    test['id'].values,\n","    test_features,\n","    VAL_TEST_TRANSFORMS,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T01:40:31.076725Z","iopub.status.busy":"2024-04-18T01:40:31.073539Z","iopub.status.idle":"2024-04-18T01:40:31.498817Z","shell.execute_reply":"2024-04-18T01:40:31.497805Z","shell.execute_reply.started":"2024-04-18T01:40:31.076656Z"},"trusted":true},"outputs":[],"source":["# Benchmark Dataset\n","N = 1\n","t_start = time.perf_counter_ns()\n","for _ in tqdm(range(N)):\n","    next(train_dataloader_iter)\n","n_images_per_second = (N * CONFIG.BATCH_SIZE) / (time.perf_counter_ns() - t_start) * 1e9\n","print(f'# Images/Second: {n_images_per_second:.0f}')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T01:40:31.501625Z","iopub.status.busy":"2024-04-18T01:40:31.500826Z","iopub.status.idle":"2024-04-18T01:40:31.769340Z","shell.execute_reply":"2024-04-18T01:40:31.768420Z","shell.execute_reply.started":"2024-04-18T01:40:31.501585Z"},"trusted":true},"outputs":[],"source":["# Example batch\n","X_batch, y_batch = next(train_dataloader_iter)\n","for k, v in X_batch.items():\n","    print(f'X_batch {k} shape: {v.shape}, dtype: {v.dtype}')\n","    print(f'X_batch {k} min: {v.min():.3f}, max: {v.max():.3f}')\n","    print(f'X_batch {k} µ: {v.float().mean():.3f}, σ: {v.float().std():.3f}')\n","# Label\n","print(f'y_batch shape: {y_batch.shape}, dtype: {y_batch.dtype}')\n","print(f'y_batch min: {y_batch.min():.3f}, max: {y_batch.max():.3f}')\n","print(f'y_batch µ: {y_batch.mean():.3f}, σ: {y_batch.std():.3f}')"]},{"cell_type":"markdown","metadata":{},"source":["# Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T01:40:31.776251Z","iopub.status.busy":"2024-04-18T01:40:31.773957Z","iopub.status.idle":"2024-04-18T01:40:31.783454Z","shell.execute_reply":"2024-04-18T01:40:31.782401Z","shell.execute_reply.started":"2024-04-18T01:40:31.776214Z"},"trusted":true},"outputs":[],"source":["# Count model parameters\n","def count_parameters(model):\n","    return sum([p.numel() for p in model.parameters()])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T01:40:31.790811Z","iopub.status.busy":"2024-04-18T01:40:31.788417Z","iopub.status.idle":"2024-04-18T01:40:31.818459Z","shell.execute_reply":"2024-04-18T01:40:31.817385Z","shell.execute_reply.started":"2024-04-18T01:40:31.790776Z"},"trusted":true},"outputs":[],"source":["class Model(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        # ImageNet Normalize Input\n","        self.normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","        \n","        # Backbone\n","        self.backbone = timm.create_model(\n","                'vit_base_patch16_224.augreg_in21k',\n","                pretrained=True,\n","                num_classes=0,\n","            )\n","        \n","        # Label\n","        self.label = nn.Sequential(\n","            nn.Linear(768,256),\n","            nn.GELU(),\n","            nn.Linear(256,CONFIG.N_TARGETS, bias=False),\n","        )\n","        \n","        # Initialize Weights\n","        self.initialize_weights()\n","        \n","    def initialize_weights(self):\n","        # Label\n","        nn.init.zeros_(self.label[2].weight)\n","        \n","    def forward(self, inputs, debug=False):\n","        if debug:\n","            embedding = self.backbone(self.normalize(inputs['image'].float() / 255))\n","            label = self.label(embedding)\n","            return {\n","                'embedding': embedding,\n","                'label': label,\n","            }\n","        else:\n","            return {\n","                'label': self.label(\n","                    self.backbone(self.normalize(inputs['image'].float() / 255))\n","                )\n","            }"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T01:40:31.826929Z","iopub.status.busy":"2024-04-18T01:40:31.823708Z","iopub.status.idle":"2024-04-18T01:40:35.004472Z","shell.execute_reply":"2024-04-18T01:40:35.003372Z","shell.execute_reply.started":"2024-04-18T01:40:31.826864Z"},"trusted":true},"outputs":[],"source":["\n","# from torchview import draw_graph\n","# model_graph = draw_graph(model.features, input_size=(1,931),device=\"cuda\")\n","# model_graph.visual_graph\n","# Clear torch cache\n","torch.cuda.empty_cache()\n","\n","# Load Weights if model is not trained\n","if not CONFIG.TRAIN_MODEL:\n","    model = torch.load('/kaggle/input/planttraits2024-eda-dataset/model.pth')\n","else:\n","    # Create new Model\n","    model = Model()\n","\n","# Model to GPU memory\n","model = model.to('cuda')\n","\n","\n","\n","print(f'# Model Parameters: {count_parameters(model):,}')\n","\n","with torch.no_grad():\n","    # Put inputs on GPU\n","    for k, v in X_batch.items():\n","        X_batch[k] = v.to('cuda')\n","    outputs = model(X_batch, debug=True)\n","    for k, v in outputs.items():\n","        print(f'outputs {k} shape: {v.shape}, min: {v.min():.3f}, max: {v.max():.3f}, µ: {v.mean():.3f}, σ: {v.std():.3f}')\n","    # Label Outputs\n","    for o in outputs['label'][:3,:]:\n","        print(o.detach().cpu().numpy().tolist())"]},{"cell_type":"markdown","metadata":{},"source":["# Learning Rate Schedule"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T01:40:35.006007Z","iopub.status.busy":"2024-04-18T01:40:35.005704Z","iopub.status.idle":"2024-04-18T01:40:35.012480Z","shell.execute_reply":"2024-04-18T01:40:35.011349Z","shell.execute_reply.started":"2024-04-18T01:40:35.005981Z"},"trusted":true},"outputs":[],"source":["# Get the learning rate scheduler\n","def get_lr_scheduler(optimizer):\n","    return torch.optim.lr_scheduler.OneCycleLR(\n","        optimizer=optimizer,\n","        max_lr=CONFIG.LR_MAX,\n","        total_steps=CONFIG.N_STEPS,\n","        pct_start=0.10,\n","        anneal_strategy='cos',\n","        div_factor=1e1,\n","        final_div_factor=1e1,\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T01:40:35.015220Z","iopub.status.busy":"2024-04-18T01:40:35.014270Z","iopub.status.idle":"2024-04-18T01:40:35.412223Z","shell.execute_reply":"2024-04-18T01:40:35.411041Z","shell.execute_reply.started":"2024-04-18T01:40:35.015182Z"},"trusted":true},"outputs":[],"source":["# Plot Learning Rate Scheduler\n","def plot_lr_scheduler():\n","    lr_scheduler = get_lr_scheduler(torch.optim.Adam(model.parameters()))\n","    lrs  = []\n","    for step in range(CONFIG.N_STEPS):\n","        lrs.append(lr_scheduler.get_last_lr())\n","        lr_scheduler.step()\n","    # Plot Learning Rate\n","    plt.figure(figsize=(12,5))\n","    plt.title('Learning Rate Schedule')\n","    plt.xlim(0, CONFIG.N_STEPS)\n","    plt.ylim(0, CONFIG.LR_MAX*1.1)\n","    plt.xlabel('Step')\n","    plt.ylabel('Learning Rate')\n","    plt.plot(lrs)\n","    plt.grid()\n","    plt.show()\n","    # Reset Learning Rate Scheduler\n","    lr_scheduler._step_count = 0\n","    lr_scheduler.last_epoch = 0\n","\n","plot_lr_scheduler()"]},{"cell_type":"markdown","metadata":{},"source":["# Metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T01:40:35.414606Z","iopub.status.busy":"2024-04-18T01:40:35.413994Z","iopub.status.idle":"2024-04-18T01:40:35.422787Z","shell.execute_reply":"2024-04-18T01:40:35.421574Z","shell.execute_reply.started":"2024-04-18T01:40:35.414562Z"},"trusted":true},"outputs":[],"source":["# Average meter to keep track of metrics/loss during training\n","class AverageMeter(object):\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val):\n","        self.sum += val.sum()\n","        self.count += val.numel()\n","        # Average is simply the sum divided by the count\n","        self.avg = self.sum / self.count"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T01:40:35.425124Z","iopub.status.busy":"2024-04-18T01:40:35.424665Z","iopub.status.idle":"2024-04-18T01:40:35.440350Z","shell.execute_reply":"2024-04-18T01:40:35.439515Z","shell.execute_reply.started":"2024-04-18T01:40:35.425083Z"},"trusted":true},"outputs":[],"source":["# Average meter to keep track of metrics/loss during training\n","class R2_METRIC(object):\n","    def __init__(self):\n","        self.reset()\n","        self.y_mean = torch.tensor(train0[CONFIG.TARGET_COLUMNS].median(axis=0).values).to('cuda')\n","\n","    def reset(self):\n","        self.avg = torch.zeros(CONFIG.N_TARGETS).to('cuda')\n","        self.rss = torch.zeros(CONFIG.N_TARGETS).to('cuda')\n","        self.tss = torch.zeros(CONFIG.N_TARGETS).to('cuda')\n","\n","    def update(self, y_pred, y_true, mean=False):\n","        self.rss += torch.sum((y_true - y_pred)**2, dim=0)\n","        self.tss += torch.sum((y_true - self.y_mean)**2, dim=0)\n","        self.avg = 1 - (self.rss / torch.maximum(self.tss, CONFIG.EPS_CUDA))"]},{"cell_type":"markdown","metadata":{},"source":["# Loss"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T01:40:35.441752Z","iopub.status.busy":"2024-04-18T01:40:35.441462Z","iopub.status.idle":"2024-04-18T01:40:35.453617Z","shell.execute_reply":"2024-04-18T01:40:35.452640Z","shell.execute_reply.started":"2024-04-18T01:40:35.441727Z"},"trusted":true},"outputs":[],"source":["# Y_SHIFT As Torch Tensor On GPU\n","Y_SHIFT_CUDA = torch.tensor(Y_SHIFT).to('cuda')\n","Y_STD_CUDA = torch.tensor(Y_STD).to('cuda')\n","# Is Log Feature Flag\n","IS_LOG_FEATURE = torch.tensor(np.isin(CONFIG.TARGET_COLUMNS, LOG_FEATURES)).to('cuda')\n","\n","def denormalize(y_pred, y_true=None):\n","    # Scale Back\n","    y_pred = (y_pred * Y_STD_CUDA) + Y_SHIFT_CUDA\n","    # Log Scale\n","    y_pred = torch.where(IS_LOG_FEATURE, 10**y_pred, y_pred)\n","    # Optionally Denormalize y_true\n","    if y_true is not None:\n","        y_true = (y_true * Y_STD_CUDA) + Y_SHIFT_CUDA\n","        y_true = torch.where(IS_LOG_FEATURE, 10**y_true, y_true)\n","        return y_pred, y_true\n","    else:\n","        return y_pred"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T01:40:35.455270Z","iopub.status.busy":"2024-04-18T01:40:35.454878Z","iopub.status.idle":"2024-04-18T01:40:35.470574Z","shell.execute_reply":"2024-04-18T01:40:35.469614Z","shell.execute_reply.started":"2024-04-18T01:40:35.455235Z"},"trusted":true},"outputs":[],"source":["# Mean feature values used to compute R2 loss\n","Y_MEDIAN = torch.tensor(CONFIG.TARGET_MEDIANS).to('cuda')\n","# Total Variation\n","MEAN_VARIATION = torch.tensor(\n","        (CONFIG.TARGET_MEDIANS - y_train_mask_raw)\n","    ).abs().mean(dim=0).to('cuda')\n","# R2 Loss\n","def r2_loss_fn(y_pred, y_true):\n","    B = len(y_pred)\n","    # Compute column wise sum of residuals and totals\n","    ss_res = (y_true - y_pred)**2\n","    ss_total = (y_true - Y_MEDIAN)**2\n","    # r2 ranging from 0 to infinity\n","    loss = torch.sum(ss_res, dim=0) / torch.maximum(torch.sum(ss_total, dim=0), CONFIG.EPS_CUDA)\n","    # Return Mean Of Loss\n","    return torch.mean(loss)\n","\n","r2_loss_fn(denormalize(outputs['label']), denormalize(y_batch.to('cuda')))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T01:40:35.476888Z","iopub.status.busy":"2024-04-18T01:40:35.476593Z","iopub.status.idle":"2024-04-18T01:40:44.732652Z","shell.execute_reply":"2024-04-18T01:40:44.731638Z","shell.execute_reply.started":"2024-04-18T01:40:35.476864Z"},"trusted":true},"outputs":[],"source":["def validation_step():\n","    # Loss Function\n","    R2_LOSS_FN = r2_loss_fn\n","    # Put model in evaluation mode\n","    model.eval()\n","    # Metrics Trackers\n","    R2 = R2_METRIC()\n","    R2_LOSS = AverageMeter()\n","    # Iterave Over Validation Set\n","    for step, (X_sample, y_true) in enumerate(val_dataloader):\n","        y_true = y_true.to('cuda')\n","        # Put label on GPU\n","        with torch.no_grad():\n","            for k, v in X_sample.items():\n","                X_sample[k] = v.to('cuda')\n","            # Forward Pass\n","            y_pred = model(X_sample)['label']\n","        # Denormalize\n","        y_pred_raw, y_true_raw = denormalize(y_pred, y_true)\n","        # Loss\n","        r2_loss = R2_LOSS_FN(y_pred_raw, y_true_raw)\n","        # Update Loss Metrics\n","        R2_LOSS.update(r2_loss)\n","        # Update Metrics\n","        R2.update(y_pred_raw, y_true_raw)\n","        # Logs\n","        r2_str = \", \".join(\n","            [f\"{f}: {v:+.3f}\" for f, v in zip(CONFIG.TARGET_COLUMNS_TEST, R2.avg)\n","        ])\n","        if not CONFIG.IS_INTERACTIVE and (step + 1) == CONFIG.N_VAL_STEPS_PER_EPOCH:\n","            print(\n","                f'VAL | R2 loss: {R2_LOSS.avg:.4f}, R2: {R2.avg.mean():.3f}, {r2_str}' + (' ' * 10)\n","            )\n","        elif CONFIG.IS_INTERACTIVE:\n","            print(\n","                f'\\rVAL {step+1:02d}/{CONFIG.N_VAL_STEPS_PER_EPOCH} | R2 loss: {R2_LOSS.avg:.4f}, ' +\n","                f'R2: {R2.avg.mean():.3f}, {r2_str}' + (' ' * 10),\n","                end='\\n' if (step + 1) == CONFIG.N_VAL_STEPS_PER_EPOCH else '', flush=True,\n","            )\n","    \n","validation_step()"]},{"cell_type":"markdown","metadata":{},"source":["# Training"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T01:40:44.734339Z","iopub.status.busy":"2024-04-18T01:40:44.733945Z","iopub.status.idle":"2024-04-18T01:40:44.775966Z","shell.execute_reply":"2024-04-18T01:40:44.774950Z","shell.execute_reply.started":"2024-04-18T01:40:44.734284Z"},"trusted":true},"outputs":[],"source":["# Loss\n","R2_LOSS_FN = r2_loss_fn\n","# Optimizer\n","optimizer = torch.optim.AdamW(\n","    params=model.parameters(),\n","    lr=CONFIG.LR_MAX,\n","    weight_decay=CONFIG.WEIGHT_DECAY,\n",")\n","# Learning Rate Scheduler\n","LR_SCHEDULER = get_lr_scheduler(optimizer)\n","# Metrics Trackers\n","R2 = R2_METRIC()\n","R2_LOSS = AverageMeter()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T01:40:44.778373Z","iopub.status.busy":"2024-04-18T01:40:44.777461Z","iopub.status.idle":"2024-04-18T02:07:35.395134Z","shell.execute_reply":"2024-04-18T02:07:35.393946Z","shell.execute_reply.started":"2024-04-18T01:40:44.778336Z"},"trusted":true},"outputs":[],"source":["if CONFIG.TRAIN_MODEL:\n","    for epoch in range(CONFIG.N_EPOCHS):\n","        # Reset Metrics\n","        R2.reset()\n","        R2_LOSS.reset()\n","        # Put model in training mode\n","        model.train()\n","        # Iterate Over Training Dataloader\n","        for step, (X_batch, y_true) in enumerate(train_dataloader):\n","            # Put batch on GPU\n","            for k, v in X_batch.items():\n","                X_batch[k] = v.to('cuda')\n","            y_true = y_true.to('cuda')\n","            # Step Time\n","            t_start = time.perf_counter_ns()\n","            # Forward Pass\n","            y_pred = model(X_batch)['label']\n","            # Denormalize\n","            y_pred_raw, y_true_raw = denormalize(y_pred, y_true)\n","            # Loss\n","            r2_loss = R2_LOSS_FN(y_pred_raw, y_true_raw)\n","            # Update Loss Metrics\n","            R2_LOSS.update(r2_loss)\n","            # Compute Gradients\n","            r2_loss.backward()\n","            # Backward Pass\n","            optimizer.step()\n","            # Zero Out Gradients\n","            optimizer.zero_grad()\n","            # Update Metrics\n","            R2.update(y_pred_raw, y_true_raw)\n","            # Compute R2 Metrics String\n","            r2_str = \", \".join([\n","                f\"{f}: {v:+.3f}\" for f, v in zip(CONFIG.TARGET_COLUMNS_TEST, R2.avg)\n","            ])\n","            # Logs\n","            if not CONFIG.IS_INTERACTIVE and (step + 1) == CONFIG.N_STEPS_PER_EPOCH:\n","                print(\n","                    f'EPOCH {epoch+1:02d} {step+1:04d}/{CONFIG.N_STEPS_PER_EPOCH} | ' + \n","                    f'R2 loss: {R2_LOSS.avg:.4f}, R2: {R2.avg.mean():+.3f}, {r2_str}, ' +\n","                    f'step: {(time.perf_counter_ns()-t_start)*1e-9:.3f}s, lr: {LR_SCHEDULER.get_last_lr()[0]:.2e}',\n","                )\n","            elif CONFIG.IS_INTERACTIVE:\n","                print(\n","                    f'\\rEPOCH {epoch+1:02d} {step+1:04d}/{CONFIG.N_STEPS_PER_EPOCH} | ' + \n","                    f'R2 loss: {R2_LOSS.avg:.4f}, R2: {R2.avg.mean():+.3f}, {r2_str}, ' +\n","                    f'step: {(time.perf_counter_ns()-t_start)*1e-9:.3f}s, lr: {LR_SCHEDULER.get_last_lr()[0]:.2e}',\n","                    end='\\n' if (step + 1) == CONFIG.N_STEPS_PER_EPOCH else '', flush=True,\n","                )\n","            # Learning Rate Scheduler Step\n","            LR_SCHEDULER.step()\n","        # Validation Step\n","        validation_step()\n","\n","# Save entire model object\n","torch.save(model, 'model.pth')"]},{"cell_type":"markdown","metadata":{},"source":["# Test"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T02:07:35.397887Z","iopub.status.busy":"2024-04-18T02:07:35.397568Z","iopub.status.idle":"2024-04-18T02:07:36.847937Z","shell.execute_reply":"2024-04-18T02:07:36.847023Z","shell.execute_reply.started":"2024-04-18T02:07:35.397857Z"},"trusted":true},"outputs":[],"source":["# Minimum And Maximum Values To Clip Predictions\n","TARGET_MIN = train0[CONFIG.TARGET_COLUMNS].values.min(axis=0)\n","TARGET_MAX = train0[CONFIG.TARGET_COLUMNS].values.max(axis=0)\n","# Submission Rows\n","SUBMISSION_ROWS = []\n","# Put Model in Evaluation Mode\n","model.eval()\n","for i, (X_sample_test, test_id) in enumerate(tqdm(test_dataset)):\n","    # Only 100 predictions in interactive mode\n","    if CONFIG.IS_INTERACTIVE and i == 100:\n","        break\n","    # Put sample on GPU and add batch dimension\n","    for k, v in X_sample_test.items():\n","        X_sample_test[k] = v.to('cuda').unsqueeze(0)\n","    # Prediction without gradients\n","    with torch.no_grad():\n","        y_pred = model(X_sample_test)['label']\n","    # Reverse Scaling\n","    y_pred, _ = denormalize(y_pred, y_pred)\n","    y_pred = y_pred.detach().cpu().numpy().squeeze()\n","    # Clip Values\n","    y_pred = np.clip(y_pred, TARGET_MIN, TARGET_MAX)\n","    # Add To Rows\n","    row = { 'id': test_id }\n","    # Add Predictions column by column\n","    for k, v in zip(CONFIG.TARGET_COLUMNS, y_pred):\n","        # Remove \"_mean\" part of target column\n","        row[k.replace('_mean', '')] = v\n","    # Add To Submission Rows\n","    SUBMISSION_ROWS.append(row)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-18T02:07:36.849583Z","iopub.status.busy":"2024-04-18T02:07:36.849195Z","iopub.status.idle":"2024-04-18T02:07:36.876568Z","shell.execute_reply":"2024-04-18T02:07:36.875694Z","shell.execute_reply.started":"2024-04-18T02:07:36.849555Z"},"trusted":true},"outputs":[],"source":["# Make Submission CSV\n","submission_df = pd.DataFrame(SUBMISSION_ROWS)\n","\n","display(submission_df.head(30))\n","\n","# Make\n","submission_df.to_csv('submission.csv', index=False)"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":8046133,"sourceId":65626,"sourceType":"competition"},{"datasetId":4468693,"sourceId":8108731,"sourceType":"datasetVersion"},{"datasetId":4819479,"sourceId":8149254,"sourceType":"datasetVersion"}],"dockerImageVersionId":30683,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
