{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":65626,"databundleVersionId":8046133,"sourceType":"competition"},{"sourceId":7526248,"sourceType":"datasetVersion","datasetId":4308295},{"sourceId":6127,"sourceType":"modelInstanceVersion","modelInstanceId":4598}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<center><img src=\"https://keras.io/img/logo-small.png\" alt=\"Keras logo\" width=\"100\"><br/>\nThis starter notebook is provided by the Keras team.</center>","metadata":{}},{"cell_type":"markdown","source":"# PlantTraits2024 - FGVC11 with [KerasCV](https://github.com/keras-team/keras-cv) and [Keras](https://github.com/keras-team/keras)\n\n> The objective of this competition is to uncover the biosphere, specifically to predict a broad set of 6 plant traits (e.g., leaf area, plant height) from crowd-sourced plant images and some ancillary data.\n\n<div align=\"center\">\n  <img src=\"https://i.ibb.co/C5zZ2nf/header.jpg\">\n</div>\n\nThis notebook guides you through the process of training and inferring a multi-input and multi-output Deep Learning model, specifically using the EfficientNetV2 backbone from KerasCV on the competition dataset. Specifically, this notebook uses both plant image data and ancillary tabular features to identify plant traits.\n\nFun fact: This notebook is backend-agnostic, supporting TensorFlow, PyTorch, and JAX. Utilizing KerasCV and Keras allows us to choose our preferred backend. Explore more details on [Keras](https://keras.io/keras_core/announcement/).\n\nIn this notebook, you will learn:\n\n- Dsigning a data pipeline for a multi-input and multi-output model.\n- Creating random augmentation pipeline with KerasCV.\n- Loading the data efficiently using [`tf.data`](https://www.tensorflow.org/guide/data).\n- Creating the model using KerasCV presets.\n- Training the model.\n- Inference and Submission on test data.\n\n**Note**: For a more in-depth understanding of KerasCV, refer to the [KerasCV guides](https://keras.io/guides/keras_cv/).","metadata":{}},{"cell_type":"markdown","source":"# 🛠 | Install Libraries  \n\nSince internet access is **disabled** during inference, we cannot install libraries in the usual `!pip install <lib_name>` manner. Instead, we need to install libraries from local files. In the following cell, we will install libraries from our local files. The installation code stays very similar - we just use the `filepath` instead of the `filename` of the library. So now the code is `!pip install <local_filepath>`. \n\n> The `filepath` of these local libraries look quite complicated, but don't be intimidated! Also `--no-deps` argument ensures that we are not installing any additional libraries.","metadata":{}},{"cell_type":"code","source":"!pip install -q /kaggle/input/kerasv3-lib-ds/keras_cv-0.8.2-py3-none-any.whl --no-deps\n!pip install -q /kaggle/input/kerasv3-lib-ds/tensorflow-2.15.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl --no-deps\n!pip install -q /kaggle/input/kerasv3-lib-ds/keras-3.0.4-py3-none-any.whl --no-deps","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-01T15:30:39.402678Z","iopub.execute_input":"2024-02-01T15:30:39.403111Z","iopub.status.idle":"2024-02-01T15:31:29.520837Z","shell.execute_reply.started":"2024-02-01T15:30:39.403063Z","shell.execute_reply":"2024-02-01T15:31:29.519681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 📚 | Import Libraries ","metadata":{}},{"cell_type":"code","source":"import os\nos.environ[\"KERAS_BACKEND\"] = \"jax\" # you can also use tensorflow or torch\n\nimport keras_cv\nimport keras\nfrom keras import ops\nimport tensorflow as tf\n\nimport cv2\nimport pandas as pd\nimport numpy as np\nfrom glob import glob\nfrom tqdm.notebook import tqdm\nimport joblib\n\nimport matplotlib.pyplot as plt ","metadata":{"execution":{"iopub.status.busy":"2024-02-01T15:31:29.522915Z","iopub.execute_input":"2024-02-01T15:31:29.523195Z","iopub.status.idle":"2024-02-01T15:31:40.139082Z","shell.execute_reply.started":"2024-02-01T15:31:29.523169Z","shell.execute_reply":"2024-02-01T15:31:40.138115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Library Versions","metadata":{}},{"cell_type":"code","source":"print(\"TensorFlow:\", tf.__version__)\nprint(\"Keras:\", keras.__version__)\nprint(\"KerasCV:\", keras_cv.__version__)","metadata":{"execution":{"iopub.status.busy":"2024-02-01T15:31:40.140429Z","iopub.execute_input":"2024-02-01T15:31:40.14158Z","iopub.status.idle":"2024-02-01T15:31:40.146671Z","shell.execute_reply.started":"2024-02-01T15:31:40.141538Z","shell.execute_reply":"2024-02-01T15:31:40.14567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ⚙️ | Configuration","metadata":{}},{"cell_type":"code","source":"class CFG:\n    verbose = 1  # Verbosity\n    seed = 42  # Random seed\n    preset = \"efficientnetv2_b2_imagenet\"  # Name of pretrained classifier\n    image_size = [224, 224]  # Input image size\n    epochs = 12 # Training epochs\n    batch_size = 96  # Batch size\n    lr_mode = \"step\" # LR scheduler mode from one of \"cos\", \"step\", \"exp\"\n    drop_remainder = True  # Drop incomplete batches\n    num_classes = 6 # Number of classes in the dataset\n    num_folds = 5 # Number of folds to split the dataset\n    fold = 0 # Which fold to set as validation data\n    class_names = ['X4_mean', 'X11_mean', 'X18_mean',\n                   'X26_mean', 'X50_mean', 'X3112_mean',]\n    aux_class_names = list(map(lambda x: x.replace(\"mean\",\"sd\"), class_names))\n    num_classes = len(class_names)\n    aux_num_classes = len(aux_class_names)","metadata":{"execution":{"iopub.status.busy":"2024-02-01T15:31:40.149618Z","iopub.execute_input":"2024-02-01T15:31:40.149959Z","iopub.status.idle":"2024-02-01T15:31:40.162873Z","shell.execute_reply.started":"2024-02-01T15:31:40.149928Z","shell.execute_reply":"2024-02-01T15:31:40.162107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ♻️ | Reproducibility \nSets value for random seed to produce similar result in each run.","metadata":{}},{"cell_type":"code","source":"keras.utils.set_random_seed(CFG.seed)","metadata":{"execution":{"iopub.status.busy":"2024-02-01T15:31:40.163849Z","iopub.execute_input":"2024-02-01T15:31:40.164089Z","iopub.status.idle":"2024-02-01T15:31:40.174536Z","shell.execute_reply.started":"2024-02-01T15:31:40.164068Z","shell.execute_reply":"2024-02-01T15:31:40.173698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 📁 | Dataset Path ","metadata":{}},{"cell_type":"code","source":"BASE_PATH = \"/kaggle/input/planttraits2024\"","metadata":{"execution":{"iopub.status.busy":"2024-02-01T15:34:52.93912Z","iopub.execute_input":"2024-02-01T15:34:52.939826Z","iopub.status.idle":"2024-02-01T15:34:52.943845Z","shell.execute_reply.started":"2024-02-01T15:34:52.939791Z","shell.execute_reply":"2024-02-01T15:34:52.942894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 📖 | Meta Data\n\nIn this dataset, we have information on `6` different plant traits. Here, **plant trait** refers to various characteristics or features of plants, such as leaf area or plant height. In this competition, we aim to predict the **average** of these traits, indicated as `X[*]_mean`, for each species. Additionally, in the training dataset, we are provided with the **standard deviation** of these traits, indicated by `X[*]_sd`, for each species. In our notebook, we will consider estimating the `mean` of traits as our main task and determining the `sd` as our auxiliary task. The description of each trait can be found in the table below:\n\n| trait_ID | trait_name                                                                                 |\n|----------|--------------------------------------------------------------------------------------------|\n| X4       | Stem specific density (SSD) or wood density (stem dry mass per stem fresh volume)          |\n| X11      | Leaf area per leaf dry mass (specific leaf area, SLA or 1/LMA)                              |\n| X18      | Plant height                                                                               |\n| X26      | Seed dry mass                                                                              |\n| X50      | Leaf nitrogen (N) content per leaf area                                                   |\n| X3112    | Leaf area (in the case of compound leaves: leaf, undefined if petiole in- or excluded)     |\n\n> **Note**: Even though in the `train.csv` file target labels / columns are named as `X[*]_mean`, in the `submission.csv` file they are named as `X[*]`.","metadata":{}},{"cell_type":"code","source":"# Train + Valid\ndf = pd.read_csv(f'{BASE_PATH}/train.csv')\ndf['image_path'] = f'{BASE_PATH}/train_images/'+df['id'].astype(str)+'.jpeg'\ndf.loc[:, CFG.aux_class_names] = df.loc[:, CFG.aux_class_names].fillna(-1)\ndisplay(df.head(2))\n\n# Test\ntest_df = pd.read_csv(f'{BASE_PATH}/test.csv')\ntest_df['image_path'] = f'{BASE_PATH}/test_images/'+test_df['id'].astype(str)+'.jpeg'\nFEATURE_COLS = test_df.columns[1:-1].tolist()\ndisplay(test_df.head(2))","metadata":{"execution":{"iopub.status.busy":"2024-02-01T15:34:55.456383Z","iopub.execute_input":"2024-02-01T15:34:55.457284Z","iopub.status.idle":"2024-02-01T15:34:58.282754Z","shell.execute_reply.started":"2024-02-01T15:34:55.457248Z","shell.execute_reply":"2024-02-01T15:34:58.281696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 🍚 | DataLoader\n\nThis DataLoader simultaneously processes JPEG `images` and tabular `features` as inputs. It also handles labels for both main and auxiliary tasks. Then, it applies augmentations such as `flip`, `rotation`, `brightness`, etc. Unlike typical augmentations, these augmentations are applied to a batch, which speeds up training and reduces CPU bottleneck.","metadata":{}},{"cell_type":"code","source":"def build_augmenter():\n    # Define augmentations\n    aug_layers = [\n        keras_cv.layers.RandomBrightness(factor=0.1, value_range=(0, 1)),\n        keras_cv.layers.RandomContrast(factor=0.1, value_range=(0, 1)),\n        keras_cv.layers.RandomSaturation(factor=(0.45, 0.55)),\n        keras_cv.layers.RandomHue(factor=0.1, value_range=(0, 1)),\n        keras_cv.layers.RandomCutout(height_factor=(0.06, 0.15), width_factor=(0.06, 0.15)),\n        keras_cv.layers.RandomFlip(mode=\"horizontal_and_vertical\"),\n        keras_cv.layers.RandomZoom(height_factor=(0.05, 0.15)),\n        keras_cv.layers.RandomRotation(factor=(0.01, 0.05)),\n    ]\n    \n    # Apply augmentations to random samples\n    aug_layers = [keras_cv.layers.RandomApply(x, rate=0.5) for x in aug_layers]\n    \n    # Build augmentation layer\n    augmenter = keras_cv.layers.Augmenter(aug_layers)\n\n    # Apply augmentations\n    def augment(inp, label):\n        images = inp[\"images\"]\n        aug_data = {\"images\": images}\n        aug_data = augmenter(aug_data)\n        inp[\"images\"] = aug_data[\"images\"]\n        return inp, label\n    return augment\n\n\ndef build_decoder(with_labels=True, target_size=CFG.image_size):\n    def decode_image(inp):\n        path = inp[\"images\"]\n        \n        # Read jpeg image\n        file_bytes = tf.io.read_file(path)\n        image = tf.io.decode_jpeg(file_bytes)\n        \n        # Resize\n        image = tf.image.resize(image, size=target_size, method=\"area\")\n        \n        # Rescale image\n        image = tf.cast(image, tf.float32)\n        image /= 255.0\n        \n        # Reshape\n        image = tf.reshape(image, [*target_size, 3])\n        \n        inp[\"images\"] = image\n        return inp\n\n    def decode_label(label, num_classes):\n        label = tf.cast(label, tf.float32)\n        label = tf.reshape(label, [num_classes])\n        return label\n\n    def decode_with_labels(inp, labels=None):\n        inp = decode_image(inp)\n        label = decode_label(labels[0], CFG.num_classes)\n        aux_label = decode_label(labels[1], CFG.aux_num_classes)\n        return (inp, (label, aux_label))\n\n    return decode_with_labels if with_labels else decode_image\n\n\ndef build_dataset(\n    paths,\n    features,\n    labels=None,\n    aux_labels=None,\n    batch_size=32,\n    cache=True,\n    decode_fn=None,\n    augment_fn=None,\n    augment=False,\n    repeat=True,\n    shuffle=1024,\n    cache_dir=\"\",\n    drop_remainder=False,\n):\n    if cache_dir != \"\" and cache is True:\n        os.makedirs(cache_dir, exist_ok=True)\n\n    if decode_fn is None:\n        decode_fn = build_decoder(labels is not None or aux_labels is not None)\n\n    if augment_fn is None:\n        augment_fn = build_augmenter()\n\n    AUTO = tf.data.experimental.AUTOTUNE\n\n    inp = {\"images\": paths, \"features\": features}\n    slices = (inp, (labels, aux_labels)) if labels is not None else inp\n\n    ds = tf.data.Dataset.from_tensor_slices(slices)\n    ds = ds.map(decode_fn, num_parallel_calls=AUTO)\n    ds = ds.cache(cache_dir) if cache else ds\n    ds = ds.repeat() if repeat else ds\n    if shuffle:\n        ds = ds.shuffle(shuffle, seed=CFG.seed)\n        opt = tf.data.Options()\n        opt.experimental_deterministic = False\n        ds = ds.with_options(opt)\n    ds = ds.batch(batch_size, drop_remainder=drop_remainder)\n    ds = ds.map(augment_fn, num_parallel_calls=AUTO) if augment else ds\n    ds = ds.prefetch(AUTO)\n    return ds","metadata":{"execution":{"iopub.status.busy":"2024-02-01T15:35:29.376058Z","iopub.execute_input":"2024-02-01T15:35:29.376426Z","iopub.status.idle":"2024-02-01T15:35:29.39702Z","shell.execute_reply.started":"2024-02-01T15:35:29.376397Z","shell.execute_reply":"2024-02-01T15:35:29.395918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 🔪 | Data Split\n\nIn the following code, we will split the data into `5` stratified folds. It first creates bins based on `6` plant traits distributions and combines them into a final bin column. Then, it uses this bin for balancing similar traits distributions across all folds.\n","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\n\nskf = StratifiedKFold(n_splits=CFG.num_folds, shuffle=True, random_state=42)\n\n# Create separate bin for each traits\nfor i, trait in enumerate(CFG.class_names):\n\n    # Determine the bin edges dynamically based on the distribution of traits\n    bin_edges = np.percentile(df[trait], np.linspace(0, 100, CFG.num_folds + 1))\n    df[f\"bin_{i}\"] = np.digitize(df[trait], bin_edges)\n\n# Concatenate the bins into a final bin\ndf[\"final_bin\"] = (\n    df[[f\"bin_{i}\" for i in range(len(CFG.class_names))]]\n    .astype(str)\n    .agg(\"\".join, axis=1)\n)\n\n# Perform the stratified split using final bin\ndf = df.reset_index(drop=True)\nfor fold, (train_idx, valid_idx) in enumerate(skf.split(df, df[\"final_bin\"])):\n    df.loc[valid_idx, \"fold\"] = fold","metadata":{"execution":{"iopub.status.busy":"2024-02-01T15:35:29.398756Z","iopub.execute_input":"2024-02-01T15:35:29.399111Z","iopub.status.idle":"2024-02-01T15:35:30.970673Z","shell.execute_reply.started":"2024-02-01T15:35:29.399073Z","shell.execute_reply":"2024-02-01T15:35:30.969597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Build Train & Valid Dataset\n\nIn the following code, we'll create **train** and **valid** data loaders. When dealing with tabular features (ancillary data), there are typically several processing steps involved. In this competition, however, the tabular data consists only of continuous, non-categorical features, which simplifies our task. Thus, we don't need to encode any categories. Before passing the tabular `features` to the model, we apply standard normalization using `StandardScaler`. This normalization step ensures that features have consistent scales, which is crucial for optimal performance of `Dense` or `Linear` layers. Readers are encouraged to experiment with advanced feature processing with raw features.\n\n> **Note**: The data loader processes (`image`, `label`) for the main task, and (`feature`, `aux_label`) for the auxiliary task.","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\n# Sample from full data\nsample_df = df.copy()\ntrain_df = sample_df[sample_df.fold != CFG.fold]\nvalid_df = sample_df[sample_df.fold == CFG.fold]\nprint(f\"# Num Train: {len(train_df)} | Num Valid: {len(valid_df)}\")\n\n# Normalize features\nscaler = StandardScaler()\ntrain_features = scaler.fit_transform(train_df[FEATURE_COLS].values)\nvalid_features = scaler.transform(valid_df[FEATURE_COLS].values)\n\n# Train\ntrain_paths = train_df.image_path.values\ntrain_labels = train_df[CFG.class_names].values\ntrain_aux_labels = train_df[CFG.aux_class_names].values\ntrain_ds = build_dataset(train_paths, train_features, train_labels, train_aux_labels,\n                         batch_size=CFG.batch_size,\n                         repeat=True, shuffle=True, augment=True, cache=False)\n\n# Valid\nvalid_paths = valid_df.image_path.values\nvalid_labels = valid_df[CFG.class_names].values\nvalid_aux_labels = valid_df[CFG.aux_class_names].values\nvalid_ds = build_dataset(valid_paths, valid_features, valid_labels, valid_aux_labels,\n                         batch_size=CFG.batch_size,\n                         repeat=False, shuffle=False, augment=False, cache=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-01T15:35:30.971977Z","iopub.execute_input":"2024-02-01T15:35:30.972719Z","iopub.status.idle":"2024-02-01T15:35:34.15313Z","shell.execute_reply.started":"2024-02-01T15:35:30.972689Z","shell.execute_reply":"2024-02-01T15:35:34.152357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset Check\n\nLet's visualize some samples and their associated labels from the dataset.","metadata":{}},{"cell_type":"code","source":"inps, tars = next(iter(train_ds))\nimgs = inps[\"images\"]\nnum_imgs, num_cols = 8, 4\n\nplt.figure(figsize=(4 * num_cols, num_imgs // num_cols * 5))\nfor i, (img, tar) in enumerate(zip(imgs[:num_imgs], tars[0][:num_imgs])):\n    plt.subplot(num_imgs // num_cols, num_cols, i + 1)\n    img = img. numpy()\n    tar = tar.numpy()\n    \n    img = (img - img.min()) / (img.max() + 1e-4)\n\n    formatted_tar = \"\\n\".join(\n        [\n            \", \".join(\n                f\"{name.replace('_mean','')}: {val:.2f}\"\n                for name, val in zip(CFG.class_names[j : j + 3], tar[j : j + 3])\n            )\n            for j in range(0, len(CFG.class_names), 3)\n        ]\n    )\n\n    plt.imshow(img)\n    plt.title(f\"[{formatted_tar}]\")\n    plt.axis(\"off\")\n\nplt.tight_layout()\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-02-01T15:35:34.155269Z","iopub.execute_input":"2024-02-01T15:35:34.155566Z","iopub.status.idle":"2024-02-01T15:35:39.601611Z","shell.execute_reply.started":"2024-02-01T15:35:34.155541Z","shell.execute_reply":"2024-02-01T15:35:39.598359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 🔍 | Loss & Metric\n\nThe evaluation metric in this competition is $R^2$ (coefficient of determination) is defined as:\n\n$$\n\\begin{equation}\n\\begin{aligned}\nR^2 &= 1 - \\frac{SS_{\\text{residual}}}{SS_{\\text{total}}} \\\\\n    &= 1 - \\frac{\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n}(y_i - \\bar{y})^2}\n\\end{aligned}\n\\end{equation}\n$$\n\nWhere:\n- $SS$ is sum of squares.\n- $n$ is the number of samples.\n- $y_i$ is the true value of the $i^{th}$ sample.\n- $\\hat{y}_i$ is the predicted value of the $i^{th}$ sample.\n- $\\bar{y}$ is the mean of the true values.\n\nIn our notebook, we will use $\\frac{SS_{residual}}{SS_{total}}$ as loss function and use $R^2$ as evaluation metric. For auxiliary task, where some samples don't have target labels, we will exclude them from the loss calculation using `use_mask` argument.","metadata":{}},{"cell_type":"code","source":"from keras import ops\n\nclass R2Loss(keras.losses.Loss):\n    def __init__(self, use_mask=False, name=\"r2_loss\"):\n        super().__init__(name=name)\n        self.use_mask = use_mask\n\n    def call(self, y_true, y_pred):\n        if self.use_mask:\n            mask = (y_true != -1)\n            y_true = ops.where(mask, y_true, 0.0)\n            y_pred = ops.where(mask, y_pred, 0.0)\n        SS_res = ops.sum(ops.square(y_true - y_pred), axis=0)  # (B, C) -> (C,)\n        SS_tot = ops.sum(ops.square(y_true - ops.mean(y_true, axis=0)), axis=0)  # (B, C) -> (C,)\n        r2_loss = SS_res / (SS_tot + 1e-6)  # (C,)\n        return ops.mean(r2_loss)  # ()\n    \nclass R2Metric(keras.metrics.Metric):\n    def __init__(self, name=\"r2\", **kwargs):\n        super(R2Metric, self).__init__(name=name, **kwargs)\n        self.SS_res = self.add_weight(name='SS_res', shape=(6,), initializer='zeros')\n        self.SS_tot = self.add_weight(name='SS_tot', shape=(6,) ,initializer='zeros')\n        self.num_samples = self.add_weight(name='num_samples', initializer='zeros')\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        SS_res = ops.sum(ops.square(y_true - y_pred), axis=0)\n        SS_tot = ops.sum(ops.square(y_true - ops.mean(y_true, axis=0)), axis=0)\n        self.SS_res.assign_add(SS_res)\n        self.SS_tot.assign_add(SS_tot)\n        self.num_samples.assign_add(ops.cast(ops.shape(y_true)[0], \"float32\"))\n\n    def result(self):\n        r2 = 1 - self.SS_res / (self.SS_tot + 1e-6)\n        return ops.mean(r2)\n\n    def reset_states(self):\n        self.total_SS_res.assign(0)\n        self.total_SS_tot.assign(0)\n        self.num_samples.assign(0)","metadata":{"execution":{"iopub.status.busy":"2024-02-01T15:35:39.602905Z","iopub.execute_input":"2024-02-01T15:35:39.603219Z","iopub.status.idle":"2024-02-01T15:35:39.617003Z","shell.execute_reply.started":"2024-02-01T15:35:39.603189Z","shell.execute_reply":"2024-02-01T15:35:39.615945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 🤖 | Modeling\n\nIn this notebook, we utilize the `EfficientNetV2 B2` backbone from KerasCV's pretrained models to extract features from images and `Dense` layers to extract features from tabular data. We then employ two `Dense` layers as our final layers (heads): one without activation (for the **main task**) and the other with `relu` activation (for the **auxiliary task**). We choose `relu` for the auxiliary task because we are estimating the **standard deviation** of plant traits, which is always **positive**. This is similar to how we use `sigmoid` activation when the target variable ranges between `0` and `1`.\n\nTo explore other backbones, simply modify the `preset` in the `CFG` (config). A list of available pretrained backbones can be found on the [KerasCV website](https://keras.io/api/keras_cv/models/).\n\n## Model Architecture Overview\n\n- Image input → Main Task → Head\n- Tabular input → Auxiliary Task → Aux Head\n\n> **Note:** We assign more weight to the `head` than the `aux_head` since it is our main task, and our evaluation metric is calculated for the `head`, not the `aux_head`.\"","metadata":{}},{"cell_type":"code","source":"# Define input layers\nimg_input = keras.Input(shape=(*CFG.image_size, 3), name=\"images\")\nfeat_input = keras.Input(shape=(len(FEATURE_COLS),), name=\"features\")\n\n# Branch for image input\nbackbone = keras_cv.models.EfficientNetV2Backbone.from_preset(CFG.preset)\nx1 = backbone(img_input)\nx1 = keras.layers.GlobalAveragePooling2D()(x1)\nx1 = keras.layers.Dropout(0.2)(x1)\n\n# Branch for tabular/feature input\nx2 = keras.layers.Dense(326, activation=\"selu\")(feat_input)\nx2 = keras.layers.Dense(64, activation=\"selu\")(x2)\nx2 = keras.layers.Dropout(0.1)(x2)\n\n# Concatenate both branches\nconcat = keras.layers.Concatenate()([x1, x2])\n\n# Output layer\nout1 = keras.layers.Dense(CFG.num_classes, activation=None, name=\"head\")(concat)\nout2 = keras.layers.Dense(CFG.aux_num_classes, activation=\"relu\", name=\"aux_head\")(concat)\nout = {\"head\": out1, \"aux_head\":out2}\n\n# Build model\nmodel = keras.models.Model([img_input, feat_input], out)\n\n# Compile the model\nmodel.compile(\n    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n    loss={\n        \"head\": R2Loss(use_mask=False),\n        \"aux_head\": R2Loss(use_mask=True), # use_mask to ignore `NaN` auxiliary labels\n    },\n    loss_weights={\"head\": 1.0, \"aux_head\": 0.3},  # more weight to main task\n    metrics={\"head\": R2Metric()}, # evaluation metric only on main task\n)\n\n# Model Summary\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-02-01T15:35:39.61828Z","iopub.execute_input":"2024-02-01T15:35:39.61863Z","iopub.status.idle":"2024-02-01T15:36:05.0974Z","shell.execute_reply.started":"2024-02-01T15:35:39.618596Z","shell.execute_reply":"2024-02-01T15:36:05.096517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot Model\n\nAs our model is multi-input and multi-output, it is difficult to understand what is going on inside the architecture. That is where `plot_model` from **Keras** can be very handy. We can draw the overall architecture, making it easier to design or recheck our architecture.","metadata":{}},{"cell_type":"code","source":"keras.utils.plot_model(model, show_shapes=True)","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2024-02-01T15:36:05.098724Z","iopub.execute_input":"2024-02-01T15:36:05.099421Z","iopub.status.idle":"2024-02-01T15:36:05.525395Z","shell.execute_reply.started":"2024-02-01T15:36:05.099385Z","shell.execute_reply":"2024-02-01T15:36:05.524502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ⚓ | LR Schedule\n\nA well-structured learning rate schedule is essential for efficient model training, ensuring optimal convergence and avoiding issues such as overshooting or stagnation.","metadata":{}},{"cell_type":"code","source":"import math\n\ndef get_lr_callback(batch_size=8, mode='cos', epochs=10, plot=False):\n    lr_start, lr_max, lr_min = 5e-5, 8e-6 * batch_size, 1e-5\n    lr_ramp_ep, lr_sus_ep, lr_decay = 3, 0, 0.75\n\n    def lrfn(epoch):  # Learning rate update function\n        if epoch < lr_ramp_ep: lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n        elif epoch < lr_ramp_ep + lr_sus_ep: lr = lr_max\n        elif mode == 'exp': lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n        elif mode == 'step': lr = lr_max * lr_decay**((epoch - lr_ramp_ep - lr_sus_ep) // 2)\n        elif mode == 'cos':\n            decay_total_epochs, decay_epoch_index = epochs - lr_ramp_ep - lr_sus_ep + 3, epoch - lr_ramp_ep - lr_sus_ep\n            phase = math.pi * decay_epoch_index / decay_total_epochs\n            lr = (lr_max - lr_min) * 0.5 * (1 + math.cos(phase)) + lr_min\n        return lr\n\n    if plot:  # Plot lr curve if plot is True\n        plt.figure(figsize=(10, 5))\n        plt.plot(np.arange(epochs), [lrfn(epoch) for epoch in np.arange(epochs)], marker='o')\n        plt.xlabel('epoch'); plt.ylabel('lr')\n        plt.title('LR Scheduler')\n        plt.show()\n\n    return keras.callbacks.LearningRateScheduler(lrfn, verbose=False)  # Create lr callback","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-02-01T15:36:05.526772Z","iopub.execute_input":"2024-02-01T15:36:05.527112Z","iopub.status.idle":"2024-02-01T15:36:05.539068Z","shell.execute_reply.started":"2024-02-01T15:36:05.527084Z","shell.execute_reply":"2024-02-01T15:36:05.538177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr_cb = get_lr_callback(CFG.batch_size, mode=CFG.lr_mode, plot=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-01T15:36:05.541886Z","iopub.execute_input":"2024-02-01T15:36:05.542172Z","iopub.status.idle":"2024-02-01T15:36:05.736534Z","shell.execute_reply.started":"2024-02-01T15:36:05.542148Z","shell.execute_reply":"2024-02-01T15:36:05.735591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 💾 | Model Checkpoint","metadata":{}},{"cell_type":"code","source":"ckpt_cb = keras.callbacks.ModelCheckpoint(\n    \"best_model.keras\",\n    monitor=\"val_head_r2\",\n    save_best_only=True,\n    save_weights_only=False,\n    mode=\"max\",\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-01T15:36:05.737837Z","iopub.execute_input":"2024-02-01T15:36:05.738208Z","iopub.status.idle":"2024-02-01T15:36:05.743321Z","shell.execute_reply.started":"2024-02-01T15:36:05.738174Z","shell.execute_reply":"2024-02-01T15:36:05.742296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 🚂 | Training","metadata":{}},{"cell_type":"code","source":"history = model.fit(\n    train_ds,\n    epochs=CFG.epochs,\n    callbacks=[lr_cb, ckpt_cb],\n    steps_per_epoch=len(train_df) // CFG.batch_size,\n    validation_data=valid_ds,\n    verbose=CFG.verbose,\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-01T15:36:05.74449Z","iopub.execute_input":"2024-02-01T15:36:05.74482Z","iopub.status.idle":"2024-02-01T15:45:47.556581Z","shell.execute_reply.started":"2024-02-01T15:36:05.744796Z","shell.execute_reply":"2024-02-01T15:45:47.555519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 📋 | Result","metadata":{}},{"cell_type":"code","source":"# Best Result\nbest_R2 = max(history.history['val_head_r2'])\nbest_Epoch = np.argmax(history.history['val_head_r2']) + 1\nprint(\"#\" * 10 + \" Result \" + \"#\" * 10)\nprint(f\"Best R2: {best_R2:.5f}\")\nprint(f\"Best Epoch: {best_Epoch}\")\nprint(\"#\" * 28)","metadata":{"execution":{"iopub.status.busy":"2024-02-01T15:45:47.557862Z","iopub.execute_input":"2024-02-01T15:45:47.558652Z","iopub.status.idle":"2024-02-01T15:45:47.568018Z","shell.execute_reply.started":"2024-02-01T15:45:47.558614Z","shell.execute_reply":"2024-02-01T15:45:47.566666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 🧪 | Prediction","metadata":{}},{"cell_type":"markdown","source":"## Load Best Model","metadata":{}},{"cell_type":"code","source":"model.load_weights(\"best_model.keras\")","metadata":{"execution":{"iopub.status.busy":"2024-02-01T15:45:47.570529Z","iopub.execute_input":"2024-02-01T15:45:47.571824Z","iopub.status.idle":"2024-02-01T15:45:59.601519Z","shell.execute_reply.started":"2024-02-01T15:45:47.571784Z","shell.execute_reply":"2024-02-01T15:45:59.600645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Build Test Dataset\n\nDon't forget to normalize for the test data as well.","metadata":{}},{"cell_type":"code","source":"# Test\ntest_paths = test_df.image_path.values\ntest_features = scaler.transform(test_df[FEATURE_COLS].values) \ntest_ds = build_dataset(test_paths, test_features, batch_size=CFG.batch_size,\n                         repeat=False, shuffle=False, augment=False, cache=False)","metadata":{"execution":{"iopub.status.busy":"2024-02-01T15:45:59.60344Z","iopub.execute_input":"2024-02-01T15:45:59.603752Z","iopub.status.idle":"2024-02-01T15:45:59.686756Z","shell.execute_reply.started":"2024-02-01T15:45:59.603727Z","shell.execute_reply":"2024-02-01T15:45:59.685757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inference\n\nAs our model outputs predictions for two tasks and our submission requires only one, we will take predictions from the main task (`head`) and ignore predictions from the auxiliary task.","metadata":{}},{"cell_type":"code","source":"preds = model.predict(test_ds)[\"head\"]","metadata":{"execution":{"iopub.status.busy":"2024-02-01T15:48:26.833178Z","iopub.execute_input":"2024-02-01T15:48:26.833587Z","iopub.status.idle":"2024-02-01T15:48:48.0593Z","shell.execute_reply.started":"2024-02-01T15:48:26.833555Z","shell.execute_reply":"2024-02-01T15:48:48.058461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 📩 | Submission","metadata":{}},{"cell_type":"code","source":"pred_df = test_df[[\"id\"]].copy()\ntarget_cols = [x.replace(\"_mean\",\"\") for x in CFG.class_names]\npred_df[target_cols] = preds.tolist()\n\nsub_df = pd.read_csv(f'{BASE_PATH}/sample_submission.csv')\nsub_df = sub_df[[\"id\"]].copy()\nsub_df = sub_df.merge(pred_df, on=\"id\", how=\"left\")\nsub_df.to_csv(\"submission.csv\", index=False)\nsub_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-01T15:48:52.646311Z","iopub.execute_input":"2024-02-01T15:48:52.646994Z","iopub.status.idle":"2024-02-01T15:48:52.920039Z","shell.execute_reply.started":"2024-02-01T15:48:52.64696Z","shell.execute_reply":"2024-02-01T15:48:52.91911Z"},"trusted":true},"execution_count":null,"outputs":[]}]}